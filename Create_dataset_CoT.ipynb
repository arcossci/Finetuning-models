{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gzN1LG6zW0Pu72ZT4g8N5UB7ZNHVklA_",
      "authorship_tag": "ABX9TyMSFmT+434UlBBEVF0NNbox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arcossci/Finetuning-models/blob/main/Create_dataset_CoT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: install packages\n",
        "\n",
        "!pip install openai PyPDF2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0UCN03IaeAy",
        "outputId": "4b402801-0e9d-4b66-db2d-8237c1ab9a64"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCzl4VLvZ98w",
        "outputId": "3298a8d2-10ad-4cb2-ead3-da7fee64b611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame created with shape: (27, 3)\n",
            "                                            Question  \\\n",
            "0  ¿Cómo se determina quiénes son las beneficiari...   \n",
            "1  ¿Cuáles son las implicaciones legales para las...   \n",
            "2  ¿Cuáles son las implicaciones legales de la te...   \n",
            "3  ¿Qué tipos de lesiones personales se considera...   \n",
            "4  ¿Cómo se determina la calidad de víctima de vi...   \n",
            "\n",
            "                                         Complex_CoT  \\\n",
            "0  1. Primero, se debe identificar el objetivo de...   \n",
            "1  1. Se inicia analizando la Ley 2172 y su objet...   \n",
            "2  Primero, se debe identificar que la tentativa ...   \n",
            "3  Primero, se debe revisar el Capítulo 111 del T...   \n",
            "4  Para responder a esta pregunta, primero es nec...   \n",
            "\n",
            "                                            Response  \n",
            "0  Las beneficiarias del subsidio de vivienda son...  \n",
            "1  Las entidades que no garanticen el acceso a su...  \n",
            "2  La tentativa de feminicidio puede tener serias...  \n",
            "3  Las lesiones personales consideradas graves so...  \n",
            "4  La calidad de víctima de violencia de género e...  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import openai\n",
        "import PyPDF2\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Set up OpenAI client\n",
        "from google.colab import userdata\n",
        "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts all text from a PDF file.\"\"\"\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def split_text_into_sections(text, max_chars=1000):\n",
        "    \"\"\"Splits text into sections of up to max_chars characters.\"\"\"\n",
        "    sections = []\n",
        "    while text:\n",
        "        if len(text) > max_chars:\n",
        "            section = text[:max_chars]\n",
        "            last_newline = section.rfind(\"\\n\")\n",
        "            if last_newline != -1:\n",
        "                section = section[:last_newline]\n",
        "            sections.append(section)\n",
        "            text = text[len(section):]\n",
        "        else:\n",
        "            sections.append(text)\n",
        "            break\n",
        "    return sections\n",
        "\n",
        "def extract_json_from_response(response):\n",
        "    \"\"\"Extracts the JSON content from an LLM response, removing code block markers.\"\"\"\n",
        "    start_marker = \"```json\"\n",
        "    end_marker = \"```\"\n",
        "    start_index = response.find(start_marker)\n",
        "    if start_index != -1:\n",
        "        start_index += len(start_marker)\n",
        "        end_index = response.find(end_marker, start_index)\n",
        "        if end_index != -1:\n",
        "            return response[start_index:end_index].strip()\n",
        "    return response.strip()\n",
        "\n",
        "def generate_cot_data(seccion_texto):\n",
        "    \"\"\"Generates CoT data from a text section using the LLM.\"\"\"\n",
        "    prompt = f\"\"\"Se te proporciona un extracto de documentos normativos sobre construcción en Colombia ley 2172 de 2021\n",
        "      Tu tarea es derivar al menos dos preguntas legales distintas y de alta calidad que un usuario (abogado, ciudadano, etc.) podría formular basándose en el contenido.\n",
        "      Sé muy creativo anticipando preguntas que los usuarios suelen hacer.\n",
        "\n",
        "      Para cada pregunta, proporciona:\n",
        "      - Question: La pregunta legal formulada a partir del texto.\n",
        "      - Complex_CoT: Dada la pregunta y respuesta, descompón el razonamiento paso a paso siguiendo el enfoque Chain-of-Thought. Explica cada paso lógico que llevó a la conclusión final.\n",
        "      - Response: Una respuesta concisa basada en el extracto.\n",
        "\n",
        "      Asegúrate de que las preguntas, el razonamiento y las respuestas sean precisos y útiles para usuarios reales.\n",
        "      No solo uses que, sino aleatoriamente: 'quién, quiénes, cuál, cuáles, cómo, cuánto, cuánta, cuántos, cuántas, dónde, cuándo, por qué' apropiadamente\n",
        "      debes inventar preguntas que sean coherentes con el texto.\n",
        "\n",
        "      Extracto:\n",
        "      {seccion_texto}\n",
        "\n",
        "      Devuelve un array JSON válido con exactamente cinco objetos. Cada objeto debe contener únicamente las claves \"Question\", \"Complex_CoT\" y \"Response\".\n",
        "\n",
        "      Salida:\n",
        "      \"\"\"\n",
        "    respuesta = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Eres un asistente experto en normatividad legal colombiana.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "    return respuesta.choices[0].message.content\n",
        "\n",
        "def main():\n",
        "    pdf_directory = \"/content/drive/MyDrive/Startup ideas/LegalTech/base\"\n",
        "    pdf_paths = glob.glob(os.path.join(pdf_directory, \"*.pdf\"))\n",
        "\n",
        "    data_records = []\n",
        "\n",
        "    for pdf_path in pdf_paths:\n",
        "        full_text = extract_text_from_pdf(pdf_path)\n",
        "        sections = split_text_into_sections(full_text)\n",
        "        for section in sections:\n",
        "            generated_output = generate_cot_data(section)\n",
        "            json_str = extract_json_from_response(generated_output)\n",
        "            try:\n",
        "                data_list = json.loads(json_str)\n",
        "                if isinstance(data_list, list):\n",
        "                    for item in data_list:\n",
        "                        if all(key in item for key in [\"Question\", \"Complex_CoT\", \"Response\"]):\n",
        "                            data_records.append(item)\n",
        "                        else:\n",
        "                            print(\"Skipping an item with missing keys:\", item)\n",
        "                else:\n",
        "                    print(\"Output is not a list:\", json_str)\n",
        "            except Exception as e:\n",
        "                print(\"Error parsing JSON:\", e)\n",
        "                print(\"Raw output:\", generated_output)\n",
        "\n",
        "    df = pd.DataFrame(data_records, columns=[\"Question\", \"Complex_CoT\", \"Response\"])\n",
        "    df.to_csv(\"cot_dataset.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"DataFrame created with shape:\", df.shape)\n",
        "    print(df.head())\n",
        "    df.to_csv(\"/content/drive/MyDrive/Startup ideas/LegalTech/CoT_dataset/cot_dataset_2.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.read_csv(\"/content/cot_dataset.csv\")\n",
        "df3.to_csv(\"/content/drive/MyDrive/Startup ideas/LegalTech/CoT_dataset/cot_dataset_1523_2012.csv\", index=False, encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "XBSFaXVT0GCy"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}